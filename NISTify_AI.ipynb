{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMd6NCwFt8RC0VOJ4zGv6p+",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sujal029/nist-analyzer-ai-agent/blob/main/NISTify_AI.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade serpapi\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5MDFnN2_d1yK",
        "outputId": "5cd6889e-e5c2-4191-d373-d67d930edef9"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: serpapi in /usr/local/lib/python3.11/dist-packages (0.1.5)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from serpapi) (2.32.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->serpapi) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->serpapi) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->serpapi) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->serpapi) (2025.4.26)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip uninstall -y serpapi\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KkSjqGiJd5Kt",
        "outputId": "64bf4a6c-1c01-4b25-e411-7cc2f1088737"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found existing installation: serpapi 0.1.5\n",
            "Uninstalling serpapi-0.1.5:\n",
            "  Successfully uninstalled serpapi-0.1.5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install git+https://github.com/serpapi/google-search-results-python.git\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 408
        },
        "id": "U8FLnS8qeMf3",
        "outputId": "d21c11c7-88b6-458c-fbb2-ec3e76d6ad90"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting git+https://github.com/serpapi/google-search-results-python.git\n",
            "  Cloning https://github.com/serpapi/google-search-results-python.git to /tmp/pip-req-build-33xfwl6l\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/serpapi/google-search-results-python.git /tmp/pip-req-build-33xfwl6l\n",
            "  Resolved https://github.com/serpapi/google-search-results-python.git to commit 264be6d62fda3e38114b7df5dfc1d3f480e58507\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from google_search_results==2.4.2) (2.32.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->google_search_results==2.4.2) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->google_search_results==2.4.2) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->google_search_results==2.4.2) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->google_search_results==2.4.2) (2025.4.26)\n",
            "Building wheels for collected packages: google_search_results\n",
            "  Building wheel for google_search_results (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for google_search_results: filename=google_search_results-2.4.2-py3-none-any.whl size=34335 sha256=6be51bc940dcad2cb7182029f038f0d5b3957f90bd0d613113dab82d3acebffa\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-apctpxzd/wheels/9a/08/98/d012fd663f2f8190b0bde004bd6f4a2666acf57da2b5ad9e70\n",
            "Successfully built google_search_results\n",
            "Installing collected packages: google_search_results\n",
            "Successfully installed google_search_results-2.4.2\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "serpapi"
                ]
              },
              "id": "e6e6ae631a7c4d539c931eec8b53a775"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip uninstall -y serpapi\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kJoMAvFaeWXc",
        "outputId": "d028d4dc-34c3-4678-b07b-3d191b2bdfad"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[33mWARNING: Skipping serpapi as it is not installed.\u001b[0m\u001b[33m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install git+https://github.com/serpapi/google-search-results-python.git\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4WnAiylOekOx",
        "outputId": "5f7d9cfe-a4e0-42f4-9616-4f7831cef6ce"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting git+https://github.com/serpapi/google-search-results-python.git\n",
            "  Cloning https://github.com/serpapi/google-search-results-python.git to /tmp/pip-req-build-435aeb8i\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/serpapi/google-search-results-python.git /tmp/pip-req-build-435aeb8i\n",
            "  Resolved https://github.com/serpapi/google-search-results-python.git to commit 264be6d62fda3e38114b7df5dfc1d3f480e58507\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from google_search_results==2.4.2) (2.32.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->google_search_results==2.4.2) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->google_search_results==2.4.2) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->google_search_results==2.4.2) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->google_search_results==2.4.2) (2025.4.26)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from serpapi import GoogleSearch\n"
      ],
      "metadata": {
        "id": "DBkv05djen6r"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from serpapi import GoogleSearch\n",
        "\n",
        "params = {\n",
        "    \"q\": \"NIST 800-171 Account Management\",\n",
        "    \"location\": \"United States\",\n",
        "    \"hl\": \"en\",\n",
        "    \"gl\": \"us\",\n",
        "    \"api_key\": \"b7b6029c0abe94ce92480d8c3bcfc9c02f3c42c154a18b421136a05a31ca244c\"\n",
        "}\n",
        "\n",
        "search = GoogleSearch(params)\n",
        "results = search.get_dict()\n",
        "for result in results.get(\"organic_results\", []):\n",
        "    print(result[\"title\"], \"-\", result[\"link\"])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K6CUWsVdeqVP",
        "outputId": "c05adc62-5771-473f-ee3a-8593d44f24fe"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "03.01.01: Account Management - https://csf.tools/reference/nist-sp-800-171/r3-0/03-01/03-01-01/\n",
            "NIST.SP.800-171r2.pdf - https://nvlpubs.nist.gov/nistpubs/SpecialPublications/NIST.SP.800-171r2.pdf\n",
            "NIST.SP.800-171r3.pdf - https://nvlpubs.nist.gov/nistpubs/SpecialPublications/NIST.SP.800-171r3.pdf\n",
            "OrgDefinedParmsNISTSP800-171.pdf - https://dodcio.defense.gov/Portals/0/Documents/CMMC/OrgDefinedParmsNISTSP800-171.pdf\n",
            "SP 800-171 - https://csrc.nist.gov/files/pubs/sp/800/171/r2/upd1/final/docs/sp800-171r2-security-reqs.xlsx\n",
            "NIST 800-171 Compliance Checklist - https://www.device42.com/compliance-standards/nist-800-171-compliance-checklist/\n",
            "3.1.1: Limit system access to authorized users, processes ... - https://csf.tools/reference/nist-sp-800-171/r2/3-1/3-1-1/\n",
            "Breaking Down NIST 800-171 Controls: The Full List of ... - https://sprinto.com/blog/list-of-nist-800-171-controls/\n",
            "Account Management from NIST 800-171 Rev 2 framework | SAMMY - https://sammy.codific.com/browse/nist-800-171-rev-2/access-control/account-management\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade google-search-results\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k4Tvj3ZokKrB",
        "outputId": "c0ccc837-901d-44c3-dcd4-a5b74fb0e303"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: google-search-results in /usr/local/lib/python3.11/dist-packages (2.4.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from google-search-results) (2.32.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->google-search-results) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->google-search-results) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->google-search-results) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->google-search-results) (2025.4.26)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install git+https://github.com/serpapi/google-search-results-python.git\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ne1x9Q7xkM_h",
        "outputId": "22919786-128d-43af-af3b-55985cb3996d"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting git+https://github.com/serpapi/google-search-results-python.git\n",
            "  Cloning https://github.com/serpapi/google-search-results-python.git to /tmp/pip-req-build-igdooaaj\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/serpapi/google-search-results-python.git /tmp/pip-req-build-igdooaaj\n",
            "  Resolved https://github.com/serpapi/google-search-results-python.git to commit 264be6d62fda3e38114b7df5dfc1d3f480e58507\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from google_search_results==2.4.2) (2.32.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->google_search_results==2.4.2) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->google_search_results==2.4.2) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->google_search_results==2.4.2) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->google_search_results==2.4.2) (2025.4.26)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from serpapi import GoogleSearch\n"
      ],
      "metadata": {
        "id": "1ah0lJQokhEn"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "params = {\n",
        "    \"q\": \"NIST 800-171 AC.L2-3.1.22 example\",\n",
        "    \"api_key\": \"b7b6029c0abe94ce92480d8c3bcfc9c02f3c42c154a18b421136a05a31ca244c\",  # Replace this with your SerpAPI key\n",
        "    \"num\": 3,\n",
        "    \"engine\": \"google\"\n",
        "}\n",
        "\n",
        "search = GoogleSearch(params)\n",
        "results = search.get_dict()\n",
        "\n",
        "for result in results.get(\"organic_results\", []):\n",
        "    print(result[\"title\"], result[\"link\"])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D4cY6XnRkRtC",
        "outputId": "b01f634c-92f9-4e80-fa90-840c70ec2e58"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "AC.L2-3.1.22 Control Public Information - DIB SCC ... https://ndisac.org/dibscc/cyberassist/cybersecurity-maturity-model-certification/level-2/ac-l2-3-1-22/\n",
            "Implementing 3.1.22 from NIST SP 800-171 Rev 2 https://www.k2grc.com/blog/implementing-3-1-22-from-nist-sp-800-171-rev-2\n",
            "AC.L2-3.1.22 - CMMC 2.11 Control Explorer https://grcacademy.io/cmmc/controls/ac-l2-3-1-22/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Install dependencies\n",
        "!pip install -q gradio sentence-transformers transformers docx2txt PyMuPDF openpyxl\n",
        "!pip install -q git+https://github.com/serpapi/google-search-results-python.git\n",
        "\n",
        "import os\n",
        "import fitz  # PyMuPDF\n",
        "import docx2txt\n",
        "import gradio as gr\n",
        "import tempfile\n",
        "import json\n",
        "import pandas as pd\n",
        "from sentence_transformers import SentenceTransformer, util\n",
        "from transformers import pipeline\n",
        "from serpapi import GoogleSearch\n",
        "\n",
        "# Load models\n",
        "sim_model = SentenceTransformer('all-mpnet-base-v2')\n",
        "qa_model = pipeline(\"question-answering\", model=\"deepset/roberta-base-squad2\")\n",
        "\n",
        "# Your SerpAPI Key (embedded)\n",
        "SERPAPI_KEY = \"b7b6029c0abe94ce92480d8c3bcfc9c02f3c42c154a18b421136a05a31ca244c\"\n",
        "\n",
        "# NIST 800-171 v3 Account Management controls\n",
        "nist_controls = [\n",
        "    {\"id\": \"AC.L1-3.1.1\", \"control\": \"Limit information system access to authorized users, processes acting on behalf of authorized users, or devices (including other information systems).\", \"improvement\": \"Ensure policy explicitly restricts system access to authorized entities only, with procedures to validate authorization.\"},\n",
        "    {\"id\": \"AC.L1-3.1.2\", \"control\": \"Limit information system access to the types of transactions and functions that authorized users are permitted to execute.\", \"improvement\": \"Add clear role-based access controls and permissions restricting user transactions/functions.\"},\n",
        "    {\"id\": \"AC.L2-3.1.6\", \"control\": \"Use non-privileged accounts or roles when accessing nonsecurity functions.\", \"improvement\": \"Define use of non-privileged accounts for everyday tasks to reduce risk of privilege misuse.\"},\n",
        "    {\"id\": \"AC.L2-3.1.7\", \"control\": \"Prevent non-privileged users from executing privileged functions and audit the execution of such functions.\", \"improvement\": \"Include audit mechanisms and technical controls preventing unauthorized privileged actions.\"},\n",
        "    {\"id\": \"AC.L2-3.1.8\", \"control\": \"Limit unsuccessful login attempts.\", \"improvement\": \"Implement account lockout or delay mechanisms after multiple failed login attempts.\"},\n",
        "    {\"id\": \"AC.L2-3.1.9\", \"control\": \"Provide privacy and security notices consistent with applicable laws before granting access.\", \"improvement\": \"Ensure policy includes explicit user notices about privacy/security obligations before access.\"},\n",
        "    {\"id\": \"AC.L2-3.1.10\", \"control\": \"Use session lock with pattern-hiding displays to prevent access/viewing after a period of inactivity.\", \"improvement\": \"Define automatic session lock policies and specify timeout periods.\"},\n",
        "    {\"id\": \"AC.L2-3.1.18\", \"control\": \"Control connection of mobile devices and personally owned devices.\", \"improvement\": \"Add restrictions and monitoring for use of personal/mobile devices on the system.\"},\n",
        "    {\"id\": \"AC.L2-3.1.20\", \"control\": \"Verify and control/limit connections to and use of external systems.\", \"improvement\": \"Establish controls for external system connections, including verification and usage restrictions.\"},\n",
        "    {\"id\": \"AC.L2-3.1.22\", \"control\": \"Control information posted or processed on publicly accessible information systems.\", \"improvement\": \"Define policies preventing unauthorized posting or processing on public systems.\"}\n",
        "]\n",
        "\n",
        "# Extract text\n",
        "def extract_text_from_file(file_obj):\n",
        "    try:\n",
        "        ext = os.path.splitext(file_obj.name)[-1].lower()\n",
        "        if ext == \".pdf\":\n",
        "            doc = fitz.open(file_obj.name)\n",
        "            return \"\\n\".join([page.get_text() for page in doc])\n",
        "        elif ext == \".docx\":\n",
        "            return docx2txt.process(file_obj.name)\n",
        "        elif ext == \".txt\":\n",
        "            return file_obj.read().decode(\"utf-8\")\n",
        "    except:\n",
        "        return \"\"\n",
        "    return \"\"\n",
        "\n",
        "# Gap analysis logic with better chunking\n",
        "def analyze_policy(file_obj):\n",
        "    text = extract_text_from_file(file_obj)\n",
        "    if not text.strip():\n",
        "        return \"‚ùå Could not extract text from uploaded file.\", None, None, None, None\n",
        "\n",
        "    chunks = [t.strip() for t in text.split('\\n') if len(t.strip()) > 30]\n",
        "    chunk_embs = sim_model.encode(chunks, convert_to_tensor=True)\n",
        "\n",
        "    results, summary_lines, explanation_lines = [], [], []\n",
        "    threshold = 0.6\n",
        "\n",
        "    for control in nist_controls:\n",
        "        control_emb = sim_model.encode(control['control'], convert_to_tensor=True)\n",
        "        sims = util.cos_sim(control_emb, chunk_embs)[0]\n",
        "        max_sim = sims.max().item()\n",
        "        rounded = round(max_sim, 3)\n",
        "\n",
        "        if max_sim < threshold:\n",
        "            status = \"Gap Found\"\n",
        "            summary_lines.append(f\"‚ùå {control['id']}: {control['control']}\")\n",
        "            explanation_lines.append(f\"Improvement: {control['improvement']}\")\n",
        "        else:\n",
        "            status = \"Covered\"\n",
        "            summary_lines.append(f\"‚úÖ {control['id']} covered\")\n",
        "\n",
        "        results.append({\n",
        "            \"Control ID\": control['id'],\n",
        "            \"Control Requirement\": control['control'],\n",
        "            \"Status\": status,\n",
        "            \"Similarity\": rounded,\n",
        "            \"Improvement Suggestion\": control['improvement'] if status == \"Gap Found\" else \"\"\n",
        "        })\n",
        "\n",
        "    df = pd.DataFrame(results)\n",
        "    json_output = json.dumps(results, indent=2)\n",
        "    excel_path = tempfile.mktemp(\".xlsx\")\n",
        "    json_path = tempfile.mktemp(\".json\")\n",
        "    txt_path = tempfile.mktemp(\".txt\")\n",
        "\n",
        "    df.to_excel(excel_path, index=False)\n",
        "    with open(json_path, \"w\") as jf:\n",
        "        jf.write(json_output)\n",
        "    with open(txt_path, \"w\") as tf:\n",
        "        tf.write(\"GAP ANALYSIS SUMMARY\\n\\n\")\n",
        "        tf.write(\"\\n\".join(summary_lines))\n",
        "        tf.write(\"\\n\\nIMPROVEMENT SUGGESTIONS\\n\\n\")\n",
        "        tf.write(\"\\n\".join(explanation_lines))\n",
        "\n",
        "    summary_text = \"\\n\".join(summary_lines) + \"\\n\\nAsk questions about your policy below.\"\n",
        "    return summary_text, excel_path, json_path, txt_path, text\n",
        "\n",
        "# Q&A fallback with SerpAPI\n",
        "def policy_qa(question, policy_text):\n",
        "    if not policy_text.strip():\n",
        "        return \"Please upload and analyze a policy document first.\"\n",
        "    try:\n",
        "        res = qa_model(question=question, context=policy_text)\n",
        "        ans, score = res.get(\"answer\", \"\"), res.get(\"score\", 0)\n",
        "        if score > 0.15 and ans.strip().lower() != \"no answer\":\n",
        "            return f\"üìÑ Answer from policy (confidence: {round(score, 2)}):\\n{ans}\"\n",
        "\n",
        "        params = {\"q\": question, \"api_key\": SERPAPI_KEY, \"engine\": \"google\", \"num\": 3}\n",
        "        results = GoogleSearch(params).get_dict().get(\"organic_results\", [])\n",
        "        if not results:\n",
        "            return \"No relevant info found in policy or web.\"\n",
        "\n",
        "        return \"**üåê Web Search Results:**\\n\" + \"\\n\".join([\n",
        "            f\"- [{r.get('title', 'No Title')}]({r.get('link', '#')})\" for r in results\n",
        "        ])\n",
        "    except Exception as e:\n",
        "        return f\"Error during Q&A: {e}\"\n",
        "\n",
        "# Gradio UI\n",
        "with gr.Blocks() as demo:\n",
        "    gr.Markdown(\"# üîê NIST 800-171 v3 Gap Analysis AI Agent\")\n",
        "    gr.Markdown(\"Upload your policy (PDF, DOCX). The AI will detect gaps and answer questions with web fallback.\")\n",
        "\n",
        "    with gr.Row():\n",
        "        policy_file = gr.File(label=\"Upload Policy\", file_types=[\".pdf\", \".docx\", ])\n",
        "        analyze_btn = gr.Button(\"Analyze Policy\")\n",
        "\n",
        "    summary_out = gr.Textbox(label=\"Gap Summary\", lines=12)\n",
        "    excel_out = gr.File(label=\"Excel Output\")\n",
        "    json_out = gr.File(label=\"JSON Output\")\n",
        "    txt_out = gr.File(label=\"Text Summary\")\n",
        "\n",
        "    gr.Markdown(\"---\")\n",
        "    gr.Markdown(\"## Ask a Question About Your Policy\")\n",
        "\n",
        "    with gr.Row():\n",
        "        question_input = gr.Textbox(label=\"Your Question\")\n",
        "        ask_btn = gr.Button(\"Ask\")\n",
        "\n",
        "    qa_out = gr.Markdown()\n",
        "\n",
        "    policy_text_store = gr.State()\n",
        "\n",
        "    analyze_btn.click(fn=analyze_policy, inputs=policy_file,\n",
        "                      outputs=[summary_out, excel_out, json_out, txt_out, policy_text_store])\n",
        "\n",
        "    ask_btn.click(fn=policy_qa, inputs=[question_input, policy_text_store], outputs=qa_out)\n",
        "\n",
        "    demo.launch()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 680
        },
        "id": "61SoWDifq1f0",
        "outputId": "7620689c-be6c-4b48-bede-7cb216676d2d"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Device set to use cpu\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "It looks like you are running Gradio on a hosted a Jupyter notebook. For the Gradio app to work, sharing must be enabled. Automatically setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://552f3ed86dc7fb0cd0.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://552f3ed86dc7fb0cd0.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ]
}