{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOun6o0FlY0goAwioa8h4nB",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sujal029/nist-analyzer-ai-agent/blob/main/NISTify_AI.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "# Set environment variable (run once in your notebook or manually)\n",
        "os.environ['SERPAPI_API_KEY'] = \"b7b6029c0abe94ce92480d8c3bcfc9c02f3c42c154a18b421136a05a31ca244c\"\n",
        "\n",
        "# Then in code, read it securely:\n",
        "api_key = os.getenv('SERPAPI_API_KEY')\n"
      ],
      "metadata": {
        "id": "mCsKMael55F4"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade serpapi\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5MDFnN2_d1yK",
        "outputId": "831a272b-dbdc-4c55-f866-00d60d97755f"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting serpapi\n",
            "  Using cached serpapi-0.1.5-py2.py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from serpapi) (2.32.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->serpapi) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->serpapi) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->serpapi) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->serpapi) (2025.4.26)\n",
            "Using cached serpapi-0.1.5-py2.py3-none-any.whl (10 kB)\n",
            "Installing collected packages: serpapi\n",
            "Successfully installed serpapi-0.1.5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip uninstall -y serpapi\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KkSjqGiJd5Kt",
        "outputId": "375991f9-aa77-4a76-d351-c863009afad1"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found existing installation: serpapi 0.1.5\n",
            "Uninstalling serpapi-0.1.5:\n",
            "  Successfully uninstalled serpapi-0.1.5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install git+https://github.com/serpapi/google-search-results-python.git\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U8FLnS8qeMf3",
        "outputId": "d6bac0ed-9a13-4523-fb17-7dd1298f8862"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting git+https://github.com/serpapi/google-search-results-python.git\n",
            "  Cloning https://github.com/serpapi/google-search-results-python.git to /tmp/pip-req-build-0sv24fo6\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/serpapi/google-search-results-python.git /tmp/pip-req-build-0sv24fo6\n",
            "  Resolved https://github.com/serpapi/google-search-results-python.git to commit 264be6d62fda3e38114b7df5dfc1d3f480e58507\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from google_search_results==2.4.2) (2.32.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->google_search_results==2.4.2) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->google_search_results==2.4.2) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->google_search_results==2.4.2) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->google_search_results==2.4.2) (2025.4.26)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip uninstall -y serpapi\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kJoMAvFaeWXc",
        "outputId": "f37d967c-c42b-4253-a561-288ccb625822"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[33mWARNING: Skipping serpapi as it is not installed.\u001b[0m\u001b[33m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install git+https://github.com/serpapi/google-search-results-python.git\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4WnAiylOekOx",
        "outputId": "5cdf0b91-8028-41cc-926c-ac4423a134b0"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting git+https://github.com/serpapi/google-search-results-python.git\n",
            "  Cloning https://github.com/serpapi/google-search-results-python.git to /tmp/pip-req-build-5mex73vv\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/serpapi/google-search-results-python.git /tmp/pip-req-build-5mex73vv\n",
            "  Resolved https://github.com/serpapi/google-search-results-python.git to commit 264be6d62fda3e38114b7df5dfc1d3f480e58507\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from google_search_results==2.4.2) (2.32.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->google_search_results==2.4.2) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->google_search_results==2.4.2) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->google_search_results==2.4.2) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->google_search_results==2.4.2) (2025.4.26)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install google-search-results\n"
      ],
      "metadata": {
        "id": "DBkv05djen6r",
        "outputId": "059a80f8-23e6-4c85-bc53-3e761d8ed8d5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: google-search-results in /usr/local/lib/python3.11/dist-packages (2.4.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from google-search-results) (2.32.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->google-search-results) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->google-search-results) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->google-search-results) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->google-search-results) (2025.4.26)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install google-search-results --quiet\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "1yk-wWW61Hj_"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip show google-search-results\n"
      ],
      "metadata": {
        "id": "iku3IFAW1zBv",
        "outputId": "e0327da7-8674-45dc-f614-851def1a9c5c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name: google_search_results\n",
            "Version: 2.4.2\n",
            "Summary: Scrape and search localized results from Google, Bing, Baidu, Yahoo, Yandex, Ebay, Homedepot, youtube at scale using SerpApi.com\n",
            "Home-page: https://github.com/serpapi/google-search-results-python\n",
            "Author: vikoky\n",
            "Author-email: victor@serpapi.com\n",
            "License: MIT\n",
            "Location: /usr/local/lib/python3.11/dist-packages\n",
            "Requires: requests\n",
            "Required-by: \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "print(sys.executable)\n"
      ],
      "metadata": {
        "id": "qdXiPt-G2VDR",
        "outputId": "cd32db63-4053-413c-83cc-000faf26b94a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/usr/bin/python3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!which pip\n"
      ],
      "metadata": {
        "id": "I5R8SbCO1WeQ",
        "outputId": "1d6093d5-e2c1-49db-9724-3edfe22b00c1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/usr/local/bin/pip\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip show google-search-results\n"
      ],
      "metadata": {
        "id": "7D7FH6wg2aSX",
        "outputId": "ce9892c7-9a02-4516-d28f-18693cf4d3ce",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name: google_search_results\n",
            "Version: 2.4.2\n",
            "Summary: Scrape and search localized results from Google, Bing, Baidu, Yahoo, Yandex, Ebay, Homedepot, youtube at scale using SerpApi.com\n",
            "Home-page: https://github.com/serpapi/google-search-results-python\n",
            "Author: vikoky\n",
            "Author-email: victor@serpapi.com\n",
            "License: MIT\n",
            "Location: /usr/local/lib/python3.11/dist-packages\n",
            "Requires: requests\n",
            "Required-by: \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!{sys.executable} -m pip install google-search-results --quiet\n"
      ],
      "metadata": {
        "id": "LreoyWco2df4"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "print(\"Python executable:\", sys.executable)\n",
        "\n",
        "!which pip\n",
        "\n",
        "!pip show google-search-results\n",
        "\n"
      ],
      "metadata": {
        "id": "IBcggVdf2k13",
        "outputId": "ad40dc83-732c-4f2a-e071-e695d429f192",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Python executable: /usr/bin/python3\n",
            "/usr/local/bin/pip\n",
            "Name: google_search_results\n",
            "Version: 2.4.2\n",
            "Summary: Scrape and search localized results from Google, Bing, Baidu, Yahoo, Yandex, Ebay, Homedepot, youtube at scale using SerpApi.com\n",
            "Home-page: https://github.com/serpapi/google-search-results-python\n",
            "Author: vikoky\n",
            "Author-email: victor@serpapi.com\n",
            "License: MIT\n",
            "Location: /usr/local/lib/python3.11/dist-packages\n",
            "Requires: requests\n",
            "Required-by: \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "!{sys.executable} -m pip install --force-reinstall google-search-results\n"
      ],
      "metadata": {
        "id": "QV3tzsj-343Q",
        "outputId": "5a6e7b80-6463-47bb-b491-7b61ca890b50",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting google-search-results\n",
            "  Using cached google_search_results-2.4.2-py3-none-any.whl\n",
            "Collecting requests (from google-search-results)\n",
            "  Downloading requests-2.32.3-py3-none-any.whl.metadata (4.6 kB)\n",
            "Collecting charset-normalizer<4,>=2 (from requests->google-search-results)\n",
            "  Downloading charset_normalizer-3.4.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (35 kB)\n",
            "Collecting idna<4,>=2.5 (from requests->google-search-results)\n",
            "  Downloading idna-3.10-py3-none-any.whl.metadata (10 kB)\n",
            "Collecting urllib3<3,>=1.21.1 (from requests->google-search-results)\n",
            "  Downloading urllib3-2.4.0-py3-none-any.whl.metadata (6.5 kB)\n",
            "Collecting certifi>=2017.4.17 (from requests->google-search-results)\n",
            "  Downloading certifi-2025.4.26-py3-none-any.whl.metadata (2.5 kB)\n",
            "Downloading requests-2.32.3-py3-none-any.whl (64 kB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m64.9/64.9 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading certifi-2025.4.26-py3-none-any.whl (159 kB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m159.6/159.6 kB\u001b[0m \u001b[31m12.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading charset_normalizer-3.4.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (147 kB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m147.3/147.3 kB\u001b[0m \u001b[31m12.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading idna-3.10-py3-none-any.whl (70 kB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m70.4/70.4 kB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading urllib3-2.4.0-py3-none-any.whl (128 kB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m128.7/128.7 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: urllib3, idna, charset-normalizer, certifi, requests, google-search-results\n",
            "  Attempting uninstall: urllib3\n",
            "    Found existing installation: urllib3 2.4.0\n",
            "    Uninstalling urllib3-2.4.0:\n",
            "      Successfully uninstalled urllib3-2.4.0\n",
            "  Attempting uninstall: idna\n",
            "    Found existing installation: idna 3.10\n",
            "    Uninstalling idna-3.10:\n",
            "      Successfully uninstalled idna-3.10\n",
            "  Attempting uninstall: charset-normalizer\n",
            "    Found existing installation: charset-normalizer 3.4.2\n",
            "    Uninstalling charset-normalizer-3.4.2:\n",
            "      Successfully uninstalled charset-normalizer-3.4.2\n",
            "  Attempting uninstall: certifi\n",
            "    Found existing installation: certifi 2025.4.26\n",
            "    Uninstalling certifi-2025.4.26:\n",
            "      Successfully uninstalled certifi-2025.4.26\n",
            "  Attempting uninstall: requests\n",
            "    Found existing installation: requests 2.32.3\n",
            "    Uninstalling requests-2.32.3:\n",
            "      Successfully uninstalled requests-2.32.3\n",
            "  Attempting uninstall: google-search-results\n",
            "    Found existing installation: google_search_results 2.4.2\n",
            "    Uninstalling google_search_results-2.4.2:\n",
            "      Successfully uninstalled google_search_results-2.4.2\n",
            "Successfully installed certifi-2025.4.26 charset-normalizer-3.4.2 google-search-results-2.4.2 idna-3.10 requests-2.32.3 urllib3-2.4.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from serpapi import GoogleSearch\n",
        "print(\"Import successful!\")\n"
      ],
      "metadata": {
        "id": "QiYFU16a3-M3",
        "outputId": "66540483-d201-4c92-8947-d479d021c656",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Import successful!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from serpapi import GoogleSearch\n",
        "\n",
        "params = {\n",
        "    \"q\": \"NIST 800-171 Account Management\",\n",
        "    \"location\": \"United States\",\n",
        "    \"hl\": \"en\",\n",
        "    \"gl\": \"us\",\n",
        "    \"api_key\": \"b7b6029c0abe94ce92480d8c3bcfc9c02f3c42c154a18b421136a05a31ca244c\"\n",
        "}\n",
        "\n",
        "search = GoogleSearch(params)\n",
        "results = search.get_dict()\n",
        "for result in results.get(\"organic_results\", []):\n",
        "    print(result[\"title\"], \"-\", result[\"link\"])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K6CUWsVdeqVP",
        "outputId": "23d1d740-5780-449b-ca94-b01837a1be13"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "03.01.01: Account Management - https://csf.tools/reference/nist-sp-800-171/r3-0/03-01/03-01-01/\n",
            "NIST.SP.800-171r2.pdf - https://nvlpubs.nist.gov/nistpubs/SpecialPublications/NIST.SP.800-171r2.pdf\n",
            "SP 800-171 - https://csrc.nist.gov/files/pubs/sp/800/171/r2/upd1/final/docs/sp800-171r2-security-reqs.xlsx\n",
            "03.01.01 ‚Äì Account Management | NIST 800-171 Rev. 3 - https://dodecacore.com/resources/blog/03.01.01\n",
            "Breaking Down NIST 800-171 Controls: The Full List of ... - https://sprinto.com/blog/list-of-nist-800-171-controls/\n",
            "OrgDefinedParmsNISTSP800-171.pdf - DoD CIO - https://dodcio.defense.gov/Portals/0/Documents/CMMC/OrgDefinedParmsNISTSP800-171.pdf\n",
            "NIST.SP.800-171r3.pdf - https://nvlpubs.nist.gov/nistpubs/SpecialPublications/NIST.SP.800-171r3.pdf\n",
            "Implementing 3.1.1 from NIST SP 800-171 Rev 2 - https://etactics.com/blog/implementing-311-from-nist-sp-800-171-rev-2\n",
            "NIST 800-171 Compliance Checklist - https://www.device42.com/compliance-standards/nist-800-171-compliance-checklist/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade google-search-results\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k4Tvj3ZokKrB",
        "outputId": "80fc4056-fab9-45db-bf5a-636748597b04"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: google-search-results in /usr/local/lib/python3.11/dist-packages (2.4.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from google-search-results) (2.32.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->google-search-results) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->google-search-results) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->google-search-results) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->google-search-results) (2025.4.26)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install git+https://github.com/serpapi/google-search-results-python.git\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ne1x9Q7xkM_h",
        "outputId": "93ac3ba8-1159-4705-d3a4-ea30077ad89a"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting git+https://github.com/serpapi/google-search-results-python.git\n",
            "  Cloning https://github.com/serpapi/google-search-results-python.git to /tmp/pip-req-build-e4j_0pgf\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/serpapi/google-search-results-python.git /tmp/pip-req-build-e4j_0pgf\n",
            "  Resolved https://github.com/serpapi/google-search-results-python.git to commit 264be6d62fda3e38114b7df5dfc1d3f480e58507\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from google_search_results==2.4.2) (2.32.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->google_search_results==2.4.2) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->google_search_results==2.4.2) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->google_search_results==2.4.2) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->google_search_results==2.4.2) (2025.4.26)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from serpapi import GoogleSearch\n"
      ],
      "metadata": {
        "id": "1ah0lJQokhEn"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "params = {\n",
        "    \"q\": \"NIST 800-171 AC.L2-3.1.22 example\",\n",
        "    \"api_key\": \"b7b6029c0abe94ce92480d8c3bcfc9c02f3c42c154a18b421136a05a31ca244c\",  # Replace this with your SerpAPI key\n",
        "    \"num\": 3,\n",
        "    \"engine\": \"google\"\n",
        "}\n",
        "\n",
        "search = GoogleSearch(params)\n",
        "results = search.get_dict()\n",
        "\n",
        "for result in results.get(\"organic_results\", []):\n",
        "    print(result[\"title\"], result[\"link\"])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D4cY6XnRkRtC",
        "outputId": "18793e4f-3612-41e4-d821-081c5b27dbbf"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "AC.L2-3.1.22 Control Public Information - DIB SCC ... https://ndisac.org/dibscc/cyberassist/cybersecurity-maturity-model-certification/level-2/ac-l2-3-1-22/\n",
            "Implementing 3.1.22 from NIST SP 800-171 Rev 2 https://www.k2grc.com/blog/implementing-3-1-22-from-nist-sp-800-171-rev-2\n",
            "AC.L2-3.1.22 - CMMC 2.11 Control Explorer https://grcacademy.io/cmmc/controls/ac-l2-3-1-22/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Install dependencies\n",
        "!pip install -q gradio sentence-transformers transformers docx2txt PyMuPDF openpyxl\n",
        "!pip install -q git+https://github.com/serpapi/google-search-results-python.git\n",
        "\n",
        "import os\n",
        "import fitz  # PyMuPDF\n",
        "import docx2txt\n",
        "import gradio as gr\n",
        "import tempfile\n",
        "import json\n",
        "import pandas as pd\n",
        "from sentence_transformers import SentenceTransformer, util\n",
        "from transformers import pipeline\n",
        "from serpapi import GoogleSearch\n",
        "\n",
        "# Load models\n",
        "sim_model = SentenceTransformer('all-mpnet-base-v2')\n",
        "qa_model = pipeline(\"question-answering\", model=\"deepset/roberta-base-squad2\")\n",
        "\n",
        "# Your SerpAPI Key (embedded)\n",
        "SERPAPI_KEY = \"b7b6029c0abe94ce92480d8c3bcfc9c02f3c42c154a18b421136a05a31ca244c\"\n",
        "\n",
        "# NIST 800-171 v3 Account Management controls\n",
        "nist_controls = [\n",
        "    {\"id\": \"AC.L1-3.1.1\", \"control\": \"Limit information system access to authorized users, processes acting on behalf of authorized users, or devices (including other information systems).\", \"improvement\": \"Ensure policy explicitly restricts system access to authorized entities only, with procedures to validate authorization.\"},\n",
        "    {\"id\": \"AC.L1-3.1.2\", \"control\": \"Limit information system access to the types of transactions and functions that authorized users are permitted to execute.\", \"improvement\": \"Add clear role-based access controls and permissions restricting user transactions/functions.\"},\n",
        "    {\"id\": \"AC.L2-3.1.6\", \"control\": \"Use non-privileged accounts or roles when accessing nonsecurity functions.\", \"improvement\": \"Define use of non-privileged accounts for everyday tasks to reduce risk of privilege misuse.\"},\n",
        "    {\"id\": \"AC.L2-3.1.7\", \"control\": \"Prevent non-privileged users from executing privileged functions and audit the execution of such functions.\", \"improvement\": \"Include audit mechanisms and technical controls preventing unauthorized privileged actions.\"},\n",
        "    {\"id\": \"AC.L2-3.1.8\", \"control\": \"Limit unsuccessful login attempts.\", \"improvement\": \"Implement account lockout or delay mechanisms after multiple failed login attempts.\"},\n",
        "    {\"id\": \"AC.L2-3.1.9\", \"control\": \"Provide privacy and security notices consistent with applicable laws before granting access.\", \"improvement\": \"Ensure policy includes explicit user notices about privacy/security obligations before access.\"},\n",
        "    {\"id\": \"AC.L2-3.1.10\", \"control\": \"Use session lock with pattern-hiding displays to prevent access/viewing after a period of inactivity.\", \"improvement\": \"Define automatic session lock policies and specify timeout periods.\"},\n",
        "    {\"id\": \"AC.L2-3.1.18\", \"control\": \"Control connection of mobile devices and personally owned devices.\", \"improvement\": \"Add restrictions and monitoring for use of personal/mobile devices on the system.\"},\n",
        "    {\"id\": \"AC.L2-3.1.20\", \"control\": \"Verify and control/limit connections to and use of external systems.\", \"improvement\": \"Establish controls for external system connections, including verification and usage restrictions.\"},\n",
        "    {\"id\": \"AC.L2-3.1.22\", \"control\": \"Control information posted or processed on publicly accessible information systems.\", \"improvement\": \"Define policies preventing unauthorized posting or processing on public systems.\"}\n",
        "]\n",
        "\n",
        "# Extract text\n",
        "def extract_text_from_file(file_obj):\n",
        "    try:\n",
        "        ext = os.path.splitext(file_obj.name)[-1].lower()\n",
        "        if ext == \".pdf\":\n",
        "            doc = fitz.open(file_obj.name)\n",
        "            return \"\\n\".join([page.get_text() for page in doc])\n",
        "        elif ext == \".docx\":\n",
        "            return docx2txt.process(file_obj.name)\n",
        "        elif ext == \".txt\":\n",
        "            return file_obj.read().decode(\"utf-8\")\n",
        "    except:\n",
        "        return \"\"\n",
        "    return \"\"\n",
        "\n",
        "# Gap analysis logic with better chunking\n",
        "def analyze_policy(file_obj):\n",
        "    text = extract_text_from_file(file_obj)\n",
        "    if not text.strip():\n",
        "        return \"‚ùå Could not extract text from uploaded file.\", None, None, None, None\n",
        "\n",
        "    chunks = [t.strip() for t in text.split('\\n') if len(t.strip()) > 30]\n",
        "    chunk_embs = sim_model.encode(chunks, convert_to_tensor=True)\n",
        "\n",
        "    results, summary_lines, explanation_lines = [], [], []\n",
        "    threshold = 0.6\n",
        "\n",
        "    for control in nist_controls:\n",
        "        control_emb = sim_model.encode(control['control'], convert_to_tensor=True)\n",
        "        sims = util.cos_sim(control_emb, chunk_embs)[0]\n",
        "        max_sim = sims.max().item()\n",
        "        rounded = round(max_sim, 3)\n",
        "\n",
        "        if max_sim < threshold:\n",
        "            status = \"Gap Found\"\n",
        "            summary_lines.append(f\"‚ùå {control['id']}: {control['control']}\")\n",
        "            explanation_lines.append(f\"Improvement: {control['improvement']}\")\n",
        "        else:\n",
        "            status = \"Covered\"\n",
        "            summary_lines.append(f\"‚úÖ {control['id']} covered\")\n",
        "\n",
        "        results.append({\n",
        "            \"Control ID\": control['id'],\n",
        "            \"Control Requirement\": control['control'],\n",
        "            \"Status\": status,\n",
        "            \"Similarity\": rounded,\n",
        "            \"Improvement Suggestion\": control['improvement'] if status == \"Gap Found\" else \"\"\n",
        "        })\n",
        "\n",
        "    df = pd.DataFrame(results)\n",
        "    json_output = json.dumps(results, indent=2)\n",
        "    excel_path = tempfile.mktemp(\".xlsx\")\n",
        "    json_path = tempfile.mktemp(\".json\")\n",
        "    txt_path = tempfile.mktemp(\".txt\")\n",
        "\n",
        "    df.to_excel(excel_path, index=False)\n",
        "    with open(json_path, \"w\") as jf:\n",
        "        jf.write(json_output)\n",
        "    with open(txt_path, \"w\") as tf:\n",
        "        tf.write(\"GAP ANALYSIS SUMMARY\\n\\n\")\n",
        "        tf.write(\"\\n\".join(summary_lines))\n",
        "        tf.write(\"\\n\\nIMPROVEMENT SUGGESTIONS\\n\\n\")\n",
        "        tf.write(\"\\n\".join(explanation_lines))\n",
        "\n",
        "    summary_text = \"\\n\".join(summary_lines) + \"\\n\\nAsk questions about your policy below.\"\n",
        "    return summary_text, excel_path, json_path, txt_path, text\n",
        "\n",
        "# Q&A fallback with SerpAPI\n",
        "def policy_qa(question, policy_text):\n",
        "    if not policy_text.strip():\n",
        "        return \"Please upload and analyze a policy document first.\"\n",
        "    try:\n",
        "        res = qa_model(question=question, context=policy_text)\n",
        "        ans, score = res.get(\"answer\", \"\"), res.get(\"score\", 0)\n",
        "        if score > 0.15 and ans.strip().lower() != \"no answer\":\n",
        "            return f\"üìÑ Answer from policy (confidence: {round(score, 2)}):\\n{ans}\"\n",
        "\n",
        "        params = {\"q\": question, \"api_key\": SERPAPI_KEY, \"engine\": \"google\", \"num\": 3}\n",
        "        results = GoogleSearch(params).get_dict().get(\"organic_results\", [])\n",
        "        if not results:\n",
        "            return \"No relevant info found in policy or web.\"\n",
        "\n",
        "        return \"**üåê Web Search Results:**\\n\" + \"\\n\".join([\n",
        "            f\"- [{r.get('title', 'No Title')}]({r.get('link', '#')})\" for r in results\n",
        "        ])\n",
        "    except Exception as e:\n",
        "        return f\"Error during Q&A: {e}\"\n",
        "\n",
        "# Gradio UI\n",
        "with gr.Blocks() as demo:\n",
        "    gr.Markdown(\"# üîê NIST 800-171 v3 Gap Analysis AI Agent\")\n",
        "    gr.Markdown(\"Upload your policy (PDF, DOCX). The AI will detect gaps and answer questions with web fallback.\")\n",
        "\n",
        "    with gr.Row():\n",
        "        policy_file = gr.File(label=\"Upload Policy\", file_types=[\".pdf\", \".docx\", ])\n",
        "        analyze_btn = gr.Button(\"Analyze Policy\")\n",
        "\n",
        "    summary_out = gr.Textbox(label=\"Gap Summary\", lines=12)\n",
        "    excel_out = gr.File(label=\"Excel Output\")\n",
        "    json_out = gr.File(label=\"JSON Output\")\n",
        "    txt_out = gr.File(label=\"Text Summary\")\n",
        "\n",
        "    gr.Markdown(\"---\")\n",
        "    gr.Markdown(\"## Ask a Question About Your Policy\")\n",
        "\n",
        "    with gr.Row():\n",
        "        question_input = gr.Textbox(label=\"Your Question\")\n",
        "        ask_btn = gr.Button(\"Ask\")\n",
        "\n",
        "    qa_out = gr.Markdown()\n",
        "\n",
        "    policy_text_store = gr.State()\n",
        "\n",
        "    analyze_btn.click(fn=analyze_policy, inputs=policy_file,\n",
        "                      outputs=[summary_out, excel_out, json_out, txt_out, policy_text_store])\n",
        "\n",
        "    ask_btn.click(fn=policy_qa, inputs=[question_input, policy_text_store], outputs=qa_out)\n",
        "\n",
        "    demo.launch(share=True)  # 'share=True' is optional for public link"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 750
        },
        "id": "61SoWDifq1f0",
        "outputId": "4f3d8a8e-fa09-4765-f282-ddc0a3efb1ae"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n",
            "Device set to use cpu\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://94c2fc81d3c58c384a.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://94c2fc81d3c58c384a.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import gradio as gr\n",
        "\n",
        "def greet(name):\n",
        "    return f\"Hello, {name}!\"\n",
        "\n",
        "demo = gr.Interface(fn=greet, inputs=\"text\", outputs=\"text\")\n",
        "demo.launch()\n"
      ],
      "metadata": {
        "id": "dXV3P8pUyzE_"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}